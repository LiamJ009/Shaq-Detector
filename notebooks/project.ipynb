{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Configure Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "\n",
    "TRAIN_DIR = 'train'\n",
    "TEST_DIR = 'test'\n",
    "FALSE_DIR = 'false'\n",
    "TRUE_DIR = 'true'\n",
    "\n",
    "# Make the directories\n",
    "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "# Make test and train directories\n",
    "os.makedirs(os.path.join(TRAIN_DIR, FALSE_DIR), exist_ok=True)\n",
    "os.makedirs(os.path.join(TRAIN_DIR, TRUE_DIR), exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.join(TEST_DIR, FALSE_DIR), exist_ok=True)\n",
    "os.makedirs(os.path.join(TEST_DIR, TRUE_DIR), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Configure LFW Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move lfw data into one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFW_DIR = 'lfw'\n",
    "\n",
    "# Path to the 'lfw_mixed' directory where all images will be moved\n",
    "lfw_mixed_dir = 'lfw_mixed'\n",
    "\n",
    "# Create 'lfw_mixed' directory if it doesn't exist\n",
    "os.makedirs(lfw_mixed_dir, exist_ok=True)\n",
    "\n",
    "# Recursively traverse the 'lfw' directory and move all images to 'lfw_mixed'\n",
    "for root, _, files in os.walk(LFW_DIR):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg')):\n",
    "            src = os.path.join(root, file)\n",
    "            dst = os.path.join(lfw_mixed_dir, file)\n",
    "            shutil.copy2(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into test and train directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "images = os.listdir(lfw_mixed_dir)\n",
    "random.shuffle(images)\n",
    "\n",
    "#num_train = int(len(images) * train_ratio)\n",
    "num_train = 1500\n",
    "\n",
    "train_images = images[:num_train]\n",
    "test_images = images[num_train:2*num_train]\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for image in train_images:\n",
    "    src = os.path.join(lfw_mixed_dir, image)\n",
    "    dst = os.path.join(TRAIN_DIR, FALSE_DIR, str(counter) + '.jpg')\n",
    "    counter += 1\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "counter = 1\n",
    "\n",
    "for image in test_images:\n",
    "    src = os.path.join(lfw_mixed_dir, image)\n",
    "    dst = os.path.join(TEST_DIR, FALSE_DIR, str(counter) + '.jpg')\n",
    "    counter += 1\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Configure Shaq Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Shaq directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAQ_DIR = 'shaq'\n",
    "SHAQ_CROPPED_DIR = 'shaq_cropped'\n",
    "\n",
    "os.makedirs(SHAQ_CROPPED_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define align and cropping algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Dlib face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Function to detect and align faces in an image with a specified padding\n",
    "def align_and_crop_face(image_path, output_path, padding=0):\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale for face detection\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    # Check if a face is detected\n",
    "    if len(faces) > 0:\n",
    "        # Assume there's only one face in the image for simplicity\n",
    "        face = faces[0]\n",
    "\n",
    "        # Get the facial landmarks for face alignment\n",
    "        shape = predictor(gray, face)\n",
    "\n",
    "        # Define the coordinates for the eyes\n",
    "        left_eye = shape.part(36)  # Left eye\n",
    "        right_eye = shape.part(45)  # Right eye\n",
    "\n",
    "        # Calculate the angle for rotation (to make eyes horizontal)\n",
    "        angle = np.arctan2(right_eye.y - left_eye.y, right_eye.x - left_eye.x)\n",
    "        angle = np.degrees(angle)\n",
    "\n",
    "        # Calculate new coordinates for cropping with padding\n",
    "        x = max(0, face.left() - padding)\n",
    "        y = max(0, face.top() - padding)\n",
    "        w = min(image.shape[1], face.right() + padding) - x\n",
    "        h = min(image.shape[0], face.bottom() + padding) - y\n",
    "\n",
    "        # Crop the image with the new coordinates\n",
    "        cropped_face = image[y:y+h, x:x+w]\n",
    "\n",
    "        # Check if the cropped face is not empty\n",
    "        if not cropped_face.size == 0:\n",
    "            # Save the aligned and cropped face\n",
    "            cv2.imwrite(output_path, cropped_face)\n",
    "        else:\n",
    "           # failed_to_crop += 1\n",
    "           pass\n",
    "    else:\n",
    "        #no_face_detected += 1\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align and crop images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(SHAQ_DIR):\n",
    "    image_path = os.path.join(SHAQ_DIR, image)\n",
    "    output_path = os.path.join(SHAQ_CROPPED_DIR, image)\n",
    "    \n",
    "    try:\n",
    "        align_and_crop_face(image_path, output_path, padding=50)\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing this cell, manually prune non-shaq images from the cropped dir. It is a long process but we need all the shaq images we can get, regardless of whether they include other people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment shaq images to get enough for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,        # Random rotation by up to 40 degrees\n",
    "    width_shift_range=0.1,   # Random horizontal shift by up to 20% of the width\n",
    "    height_shift_range=0.1,  # Random vertical shift by up to 20% of the height\n",
    "    shear_range=0.2,         # Shear transformations\n",
    "    zoom_range=0.2,          # Random zoom in/out by up to 20%\n",
    "    horizontal_flip=True,    # Random horizontal flip\n",
    "    brightness_range=[0.2,1.0],\n",
    "    fill_mode='nearest'      # Fill empty areas after transformations\n",
    ")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "output_directory = 'shaq_augmented'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# List all \"shaq\" image files in the directory\n",
    "shaq_image_files = [os.path.join(SHAQ_CROPPED_DIR, filename) for filename in os.listdir(SHAQ_CROPPED_DIR)]\n",
    "\n",
    "# Specify the number of augmentations per image\n",
    "n_augmentations = 5  # You can adjust this number as needed\n",
    "\n",
    "# Apply augmentation to each \"shaq\" image and save the augmented images\n",
    "for image_path in shaq_image_files:\n",
    "    \n",
    "    try:\n",
    "        img = load_img(image_path)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)  # Reshape for flow method\n",
    "\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1):\n",
    "            augmented_image = array_to_img(batch[0])\n",
    "            filename = os.path.basename(image_path)\n",
    "            augmented_image.save(os.path.join(output_directory, f'augmented_{i}_{filename}'))\n",
    "            i += 1\n",
    "            if i >= n_augmentations:\n",
    "                break\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort into test and train directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(output_directory)\n",
    "random.shuffle(images)\n",
    "\n",
    "num_train = int(len(images) * train_ratio)\n",
    "\n",
    "train_images = images[:num_train]\n",
    "test_images = images[num_train:]\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for image in train_images:\n",
    "    src = os.path.join(output_directory, image)\n",
    "    dst = os.path.join(TRAIN_DIR, TRUE_DIR, str(counter) + '.jpg')\n",
    "    counter += 1\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "counter = 1\n",
    "\n",
    "for image in test_images:\n",
    "    src = os.path.join(output_directory, image)\n",
    "    dst = os.path.join(TEST_DIR, TRUE_DIR, str(counter) + '.jpg')\n",
    "    counter += 1\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Import Data into Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=64\n",
    "ROWS = 256\n",
    "COLS = 256\n",
    "CHANNELS = 3\n",
    "batch_size= 64\n",
    "Data_dir = 'train'\n",
    "Test_DIR = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data into keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  Data_dir,\n",
    "  validation_split=0.2, \n",
    "  subset=\"training\", \n",
    "  seed=123,\n",
    "  image_size=(ROWS, COLS),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  Data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(ROWS, COLS),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Configure CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define base model for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the weights and biases of the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add additional dense layers for the shaq detection activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Optional dropout layer to reduce overfitting\n",
    "    layers.Dense(2, activation='softmax')  # Output layer for binary classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define callback function and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback function to monitor the loss and stop training if loss does not decrease for 5 consecutive epochs\n",
    "\n",
    "callback =tf.keras.callbacks.EarlyStopping(\n",
    "  monitor='val_loss', min_delta=0.0000001, patience=5)\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('savedmodel') # savedmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View model training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot( val_acc, label='Validation Accuracy')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load testing data into keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images for Testing\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  Test_DIR,\n",
    "  validation_split=0.0,\n",
    "  seed=123,\n",
    "  image_size=(ROWS, COLS),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine accuracy of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions on the test data\n",
    "y_true = []  # True labels\n",
    "y_pred = []  # Predicted labels\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    y_true.extend(labels.numpy())\n",
    "    predictions = model.predict(images)\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy by age range/class\n",
    "class_accuracies = []\n",
    "for class_label in range(num_classes):\n",
    "    correct = sum(y_true[i] == class_label and y_pred[i] == class_label for i in range(len(y_true)))\n",
    "    total_samples = sum(y_true[i] == class_label for i in range(len(y_true)))\n",
    "    class_accuracy = correct / total_samples if total_samples > 0 else 0.0  # Avoid division by zero\n",
    "    class_accuracies.append(class_accuracy)\n",
    "    print(f\"Accuracy for Class {class_label}: {class_accuracy:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
